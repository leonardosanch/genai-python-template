# Prompt de ValidaciÃ³n de Skills para Claude Code

Este prompt debe ser ejecutado por una IA para validar que todos los skills sean consistentes con el CLAUDE.md base y no introduzcan riesgos de alucinaciÃ³n.

---

## PROMPT DE VALIDACIÃ“N

```
ActÃºa como un **Senior AI Engineer** especializado en prevenciÃ³n de alucinaciones en sistemas LLM. Tu misiÃ³n es revisar skills de Claude Code (.md) para verificar que sean consistentes con el CLAUDE.md base y no introduzcan riesgos de alucinaciÃ³n cuando Claude genere cÃ³digo Python backend para sistemas GenAI.

## CONTEXTO: CLAUDE.md Base (Resumen de PolÃ­ticas Clave)

El proyecto usa este archivo base con reglas estrictas anti-alucinaciÃ³n:

### ğŸ”´ Reglas Absolutas del Base
1. **Nunca inventar APIs, mÃ©todos o funciones** - Si no hay 100% certeza, declarar "Verificar en documentaciÃ³n: [link]"
2. **Versionado explÃ­cito obligatorio** - Especificar versiones mÃ­nimas, marcar APIs inestables con `âš ï¸`
3. **Honestidad epistÃ©mica** - "No estoy seguro de [X], verificar en [fuente]"

### ğŸ“‹ LibrerÃ­as Marcadas como Inestables (Requieren VerificaciÃ³n)
| LibrerÃ­a | Estabilidad | AcciÃ³n Requerida |
|----------|-------------|------------------|
| langchain | âš ï¸ Cambia frecuentemente | Verificar imports |
| langchain_experimental | âŒ Muy inestable | Verificar existencia de clases |
| langgraph | âš ï¸ EstabilizÃ¡ndose | Verificar changelog |
| deepeval | âš ï¸ API cambia | Verificar docs antes de usar |
| guardrails-ai | âš ï¸ Inestable | Verificar docs actuales |
| crewai | âš ï¸ En desarrollo | Verificar versiÃ³n |

### ğŸ—ï¸ Arquitectura Base (Clean Architecture)
- `domain`: pura lÃ³gica de negocio, sin frameworks
- `application`: casos de uso y orquestaciÃ³n
- `infrastructure`: sistemas externos (LLMs, DBs, cloud, MCP)
- `interfaces`: APIs, CLI, controllers
- **Nunca** filtrar infraestructura al dominio

### âš¡ Async Obligatorio
- Todas las llamadas LLM deben ser async (`await`)
- Usar `asyncio.gather` para paralelismo
- Usar `asyncio.Semaphore` para rate limiting
- **Nunca** bloquear el event loop con I/O sÃ­ncrono

---

## INSTRUCCIONES DE REVISIÃ“N

Para cada skill proporcionado, evalÃºa:

### 1. CONSISTENCIA CON CLAUDE.md BASE
- [ ] Â¿Respeta la estructura de Clean Architecture (domain/application/infra/interfaces)?
- [ ] Â¿Mantiene el principio "domain never depends on infrastructure"?
- [ ] Â¿Usa async/await consistentemente para operaciones I/O?
- [ ] Â¿Sigue las convenciones de nombres y patrones del base?

### 2. CUMPLIMIENTO DE POLÃTICAS ANTI-ALUCINACIÃ“N
- [ ] **Â¿ProhÃ­be explÃ­citamente inventar APIs?** Debe tener equivalente a: "Si no estÃ¡s 100% seguro â†’ declarar incertidumbre"
- [ ] **Â¿Requiere versionado explÃ­cito?** Debe especificar versiones mÃ­nimas de dependencias
- [ ] **Â¿Marca APIs inestables?** Debe usar `âš ï¸` o `âŒ` segÃºn tabla del base
- [ ] **Â¿Promueve honestidad epistÃ©mica?** Debe forzar a Claude a admitir cuando no sabe

### 3. MANEJO DE LIBRERÃAS INESTABLES
Para cada librerÃ­a inestable mencionada en el skill:
- [ ] Â¿Verifica que los imports existan antes de usarlos?
- [ ] Â¿Incluye bloques try/except para ImportError con mensajes descriptivos?
- [ ] Â¿Referencias a documentaciÃ³n oficial actualizada?
- [ ] Â¿Advertencias sobre breaking changes conocidos?

### 4. PREVENCIÃ“N DE ALUCINACIONES ESPECÃFICAS EN CÃ“DIGO

#### A. Python / FastAPI
- [ ] Â¿Evita inventar parÃ¡metros en funciones de librerÃ­as estÃ¡ndar?
- [ ] Â¿Verifica que los decorators de FastAPI existan (@app.get, @app.post)?
- [ ] Â¿No asume comportamientos de SQLAlchemy 2.0 vs 1.x sin verificar?

#### B. LLM / GenAI Frameworks
- [ ] Â¿No inventa mÃ©todos en LangChain/LangGraph (ej: `chain.run()` vs `chain.invoke()`)?
- [ ] Â¿Verifica que los nodos de LangGraph tengan la signature correcta?
- [ ] Â¿No asume que CrewAI/AutoGen tienen APIs que cambiaron recientemente?

#### C. Pydantic / Structured Output
- [ ] Â¿Usa `model_validate` vs `parse_obj` segÃºn versiÃ³n de Pydantic v2?
- [ ] Â¿Verifica que los tipos de Instructor sean compatibles con la versiÃ³n?

### 5. PATRONES DE SEGURIDAD ANTI-HALLUCINACIÃ“N

Verifica que el skill incluya:

```python
# PatrÃ³n de respuesta segura (del base)
try:
    from libreria_inestable.modulo import Clase
    FEATURE_AVAILABLE = True
except ImportError:
    FEATURE_AVAILABLE = False

if not FEATURE_AVAILABLE:
    raise RuntimeError("Requiere X. Verificar versiÃ³n compatible.")
```

- [ ] Â¿Incluye este patrÃ³n o equivalente para dependencias inestables?
- [ ] Â¿Nunca hardcodea precios de LLM, dimensiones de embeddings, URLs de APIs?
- [ ] Â¿Usa variables de entorno para toda configuraciÃ³n sensible?

### 6. CALIDAD DE EJEMPLOS DE CÃ“DIGO
- [ ] Â¿Los ejemplos son verificables? (pueden ejecutarse copiando y pegando)
- [ ] Â¿Incluyen imports explÃ­citos al inicio?
- [ ] Â¿Especifican versiones de dependencias en comentarios?
- [ ] Â¿Evitan "..." o "# implementar aquÃ­" en cÃ³digo crÃ­tico?

---

## FORMATO DE RESPUESTA

Para cada skill revisado, entrega:

### ğŸ“Š SCORECARD DE CONFIABILIDAD

| Criterio | Score (1-10) | Evidencia |
|----------|--------------|-----------|
| Consistencia con Base | X/10 | [Cita especÃ­fica del skill] |
| Cumplimiento Anti-AlucinaciÃ³n | X/10 | [Cita especÃ­fica del skill] |
| Manejo de LibrerÃ­as Inestables | X/10 | [Cita especÃ­fica del skill] |
| Calidad de Ejemplos | X/10 | [Cita especÃ­fica del skill] |
| **PROMEDIO GENERAL** | **X/10** | |

### ğŸš¨ HALLAZGOS CRÃTICOS (Bloqueantes)

Lista de problemas que deben corregirse antes de usar el skill:

```
[CRÃTICO] [DescripciÃ³n del problema] â†’ [LÃ­nea o secciÃ³n especÃ­fica]
Riesgo: [QuÃ© podrÃ­a alucinar Claude]
Fix sugerido: [Texto exacto a cambiar]
```

### âš ï¸ ADVERTENCIAS (No bloqueantes pero riesgosas)

```
[ADVERTENCIA] [DescripciÃ³n] â†’ [UbicaciÃ³n]
MitigaciÃ³n sugerida: [AcciÃ³n recomendada]
```

### ğŸ”§ RECOMENDACIONES DE MEJORA

Cambios opcionales para robustez adicional:
- [Sugerencia especÃ­fica con ejemplo de redacciÃ³n]

### âœ… CHECKLIST DE VALIDACIÃ“N FINAL

Antes de aprobar el skill, verificar:
- [ ] Todas las librerÃ­as inestables tienen warnings
- [ ] Los ejemplos de cÃ³digo incluyen versiones de dependencias
- [ ] Hay al menos un patrÃ³n de "honestidad epistÃ©mica" explÃ­cito
- [ ] El skill no contradice ninguna regla del CLAUDE.md base
- [ ] Async/await se usa correctamente en operaciones I/O

---

## EJEMPLO DE OUTPUT ESPERADO

**Skill revisado:** `docs/skills/multi_agent_systems.md`
**Score General:** 7.5/10

**Hallazgo CrÃ­tico:**
LangGraph menciona `StateGraph.add_node()` sin verificar versiÃ³n. En 0.1.x vs 0.2.x cambia la API de compilaciÃ³n.
**Fix:** Agregar "âš ï¸ Verificar versiÃ³n de LangGraph. En 0.2.x usar `graph.compile()` vs `graph.run()`"

**Advertencia:**
CrewAI no tiene disclaimer de inestabilidad pese a estar en la tabla del base.

**RecomendaciÃ³n:**
Agregar bloque de verificaciÃ³n de imports para langgraph al inicio de ejemplos.

---

## CONTEXTO ADICIONAL

El usuario aplica rigor similar al que usa para evaluar sesgos en anÃ¡lisis econÃ³micos. Valora:
- **Transparencia** cuando la IA no sabe algo
- **PrecisiÃ³n tÃ©cnica** sobre velocidad de respuesta
- **Verificabilidad** de todo cÃ³digo generado
```

---

## LISTA DE SKILLS A VALIDAR

Ejecutar el prompt anterior para cada uno de estos archivos:

1. `docs/skills/software_architecture.md`
2. `docs/skills/security.md`
3. `docs/skills/genai_rag.md`
4. `docs/skills/multi_agent_systems.md`
5. `docs/skills/data_ml_engineering.md`
6. `docs/skills/api_streaming.md`
7. `docs/skills/cloud_infrastructure.md`
8. `docs/skills/testing_quality.md`
9. `docs/skills/observability_monitoring.md`
10. `docs/skills/databases.md`
11. `docs/skills/event_driven_systems.md`
12. `docs/skills/mcp.md`
13. `docs/skills/governance.md`
14. `docs/skills/context_engineering.md`
15. `docs/skills/prompt_engineering.md`
16. `docs/skills/hallucination_detection.md`
17. `docs/skills/multi_tenancy.md`
18. `docs/skills/automation.md`
19. `docs/skills/analytics.md`

---

## ENTREGABLES ESPERADOS

Al finalizar la validaciÃ³n de todos los skills:

### 1. Tabla Resumen de Scores

| Skill | Score | CrÃ­ticos | Advertencias | Estado |
|-------|-------|----------|--------------|--------|
| software_architecture.md | X/10 | N | N | âœ…/âš ï¸/âŒ |
| security.md | X/10 | N | N | âœ…/âš ï¸/âŒ |
| ... | ... | ... | ... | ... |

### 2. Lista Consolidada de Fixes

Todos los hallazgos crÃ­ticos agrupados por prioridad:
- **P0 (Bloqueante):** [Lista]
- **P1 (Importante):** [Lista]
- **P2 (Mejora):** [Lista]

### 3. Prompts de RemediaciÃ³n

Para cada hallazgo crÃ­tico, generar un prompt especÃ­fico que otra IA pueda ejecutar para corregirlo.

Formato:
```
### Fix para [Skill]: [DescripciÃ³n corta]

Lee el archivo `docs/skills/[skill].md` y realiza el siguiente cambio:

**UbicaciÃ³n:** [SecciÃ³n o lÃ­nea]
**Cambio:** [InstrucciÃ³n especÃ­fica]
**Texto actual:** [Si aplica]
**Texto nuevo:** [Texto exacto a insertar]

No modifiques ningÃºn otro contenido del archivo.
```
